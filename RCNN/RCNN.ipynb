{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RCNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmZwLwbnxIKo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "523253fc-47e4-4f29-f814-149938a35479"
      },
      "source": [
        "!pip install numpy_indexed"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy_indexed\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/90/fe830d577400954db57a88f7022efef095745e1df4256ca5171d659d4177/numpy_indexed-0.3.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from numpy_indexed) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from numpy_indexed) (0.16.0)\n",
            "Installing collected packages: numpy-indexed\n",
            "Successfully installed numpy-indexed-0.3.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYIlk4IpyTR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import ast\n",
        "import os\n",
        "from PIL import Image\n",
        "import time\n",
        "import copy\n",
        "import numpy_indexed as npi"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXrr2WwaxPDm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a2329af-e1ca-4067-dfba-107cf4322415"
      },
      "source": [
        "a = np.asarray([[4, 6, 6],[4, 4, 4]])\n",
        "b = np.asarray([[6, 6, 6,4],[4, 3, 2, 4]])\n",
        "count = 0\n",
        "for i in range(a.shape[0]):\n",
        "  count += min(npi.in_(a[i, :], b[i, :]).sum(), npi.in_(b[i, :], a[i, :]).sum())\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAAVmJmrzHHp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "3fdf7b02-8449-4351-c4ff-224409c14857"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNd1XdOwxC70",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8fe9c24d-6626-4811-91fe-8db209507d86"
      },
      "source": [
        "# Get parts list - use indices of each part as \"label\", for one-hot encoding\n",
        "parts_list = []\n",
        "with open('/content/drive/My Drive/APS360 Project/share/Data/Input/Datasets/BerendPartsList') as f:\n",
        "  for line in f:\n",
        "    word = line[:len(line) - 1] # get rid of '\\n\n",
        "    parts_list.append(int(word))\n",
        "\n",
        "print(len(parts_list))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FlDvML_CAwA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "csv_path = '/content/drive/My Drive/APS360 Project/share/Data/Input/Datasets/Berend/CSV/labels.csv'\n",
        "image_path = '/content/drive/My Drive/APS360 Project/share/Data/Input/Datasets/Berend/Images'\n",
        "bbox_label_root = '/content/drive/My Drive/APS360 Project/finalOutput'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mb0ymDcI8I1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BerendDataset(Dataset):\n",
        "  # For our dataset, let us accept a CSV file as input\n",
        "  # + a list of parts, for a one-hot encoding.\n",
        "  # We will also accept a root directory for images. \n",
        "  # We also accept transformations to the image\n",
        "  def __init__(self, csv_path, parts_list, image_root, transforms, bbox_root):\n",
        "    self.csv_path = csv_path\n",
        "    self.parts_list = parts_list\n",
        "    self.image_root = image_root\n",
        "    data = pandas.read_csv(csv_path)\n",
        "    # Convert label col to list of ints of part numbers:\n",
        "    for i in range(len(data[\"Labels\"])):\n",
        "      label = data[\"Labels\"][i]\n",
        "      list_row = ast.literal_eval(label)\n",
        "      int_list = list(map(int, list_row))\n",
        "      data[\"Labels\"][i] = list(map(lambda x: parts_list.index(x), int_list))\n",
        "\n",
        "    # Do same for Color column:\n",
        "    for i in range(len(data[\"Color\"])):\n",
        "      label = data[\"Color\"][i]\n",
        "      list_row = ast.literal_eval(label)\n",
        "      data[\"Color\"][i] = torch.LongTensor(list(map(int, list_row)))\n",
        "    \n",
        "    self.data = data\n",
        "    self.transforms = transforms\n",
        "    self.bbox_root = bbox_root\n",
        "    self.bbox_tracked = {}\n",
        "    self._BBOX_COL_NAMES = [\"Labels\", \"x_min\", \"y_min\", \"x_max\", \"y_max\"]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    target = {}\n",
        "    labels = self.data[\"Labels\"][idx]\n",
        "\n",
        "    filename = self.data[\"Name\"][idx]\n",
        "    #print(filename)\n",
        "    img_path = os.path.join(self.image_root, filename + '.jpg')\n",
        "    bbox_path = os.path.join(self.bbox_root, filename + '.csv')\n",
        "\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    if self.transforms is not None:\n",
        "      img = self.transforms(img)\n",
        "\n",
        "    target[\"labels\"] = torch.LongTensor(labels)\n",
        "\n",
        "    if filename in self.bbox_tracked:\n",
        "      bboxes = self.bbox_tracked[filename]\n",
        "    else:\n",
        "      bbox_data = pandas.read_csv(os.path.join(self.bbox_root, filename + '.csv'),\n",
        "                                  skiprows=2,\n",
        "                                  header=None,\n",
        "                                  names=self._BBOX_COL_NAMES)\n",
        "      bbox_data_np = bbox_data.to_numpy(dtype=np.int_)\n",
        "      bbox_labels = bbox_data_np[:, 0]\n",
        "      bbox_targets = bbox_data_np[:, 1:]\n",
        "      bboxes = torch.zeros([len(labels), 4], dtype=torch.long)\n",
        "      for i in range(len(bbox_labels)):\n",
        "        bboxes[i, :] = torch.LongTensor(bbox_targets[i])\n",
        "      self.bbox_tracked[filename] = bboxes\n",
        "\n",
        "    target[\"boxes\"] = bboxes\n",
        "    \n",
        "    return img, target\n",
        "  def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnhO_e3ZLhRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_transform = transforms.Compose([transforms.Resize((375, 500)), transforms.ToTensor()])\n",
        "dataset = BerendDataset(csv_path=csv_path, parts_list=parts_list, image_root=image_path, transforms=data_transform, bbox_root=bbox_label_root)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmHpr28ahNpn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f779c365-d01b-4af5-8e82-024fce230a90"
      },
      "source": [
        "my_data = dataset.data\n",
        "my_data_labels = my_data[\"Labels\"]\n",
        "label_lengths = {}\n",
        "for label in my_data_labels:\n",
        "  length = len(label)\n",
        "  if (length not in label_lengths):\n",
        "    label_lengths[length] = 1\n",
        "  else:\n",
        "    label_lengths[length] += 1\n",
        "print(label_lengths)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 152, 2: 135, 3: 116, 4: 95, 5: 87, 6: 72, 7: 57, 8: 42, 9: 33, 10: 27}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4LaqHNYkqYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image, target = dataset[9]\n",
        "# img = np.transpose(image, [1, 2, 0])\n",
        "# plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4keoHcCJn2LS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxIe2VOtErHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.roi_heads.box_predictor.cls_score = nn.Linear(in_features=1024, out_features=len(parts_list), bias=True)\n",
        "model.roi_heads.box_predictor.bbox_pred = nn.Linear(in_features=1024, out_features=4*len(parts_list), bias=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTSNniRmlCpp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f3690ca4-7e3d-4211-ffd5-725d6f1ab109"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FasterRCNN(\n",
            "  (transform): GeneralizedRCNNTransform(\n",
            "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
            "  )\n",
            "  (backbone): BackboneWithFPN(\n",
            "    (body): IntermediateLayerGetter(\n",
            "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "      (bn1): FrozenBatchNorm2d()\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "      (layer1): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d()\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d()\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d()\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): FrozenBatchNorm2d()\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d()\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d()\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d()\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d()\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d()\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d()\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer2): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d()\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d()\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d()\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): FrozenBatchNorm2d()\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d()\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d()\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d()\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d()\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d()\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d()\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d()\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d()\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d()\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer3): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d()\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d()\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d()\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): FrozenBatchNorm2d()\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d()\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d()\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d()\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d()\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d()\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d()\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d()\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d()\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d()\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (4): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d()\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d()\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d()\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (5): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d()\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d()\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d()\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer4): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d()\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d()\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d()\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): FrozenBatchNorm2d()\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d()\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d()\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d()\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d()\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d()\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d()\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (fpn): FeaturePyramidNetwork(\n",
            "      (inner_blocks): ModuleList(\n",
            "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (layer_blocks): ModuleList(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "      (extra_blocks): LastLevelMaxPool()\n",
            "    )\n",
            "  )\n",
            "  (rpn): RegionProposalNetwork(\n",
            "    (anchor_generator): AnchorGenerator()\n",
            "    (head): RPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): RoIHeads(\n",
            "    (box_roi_pool): MultiScaleRoIAlign()\n",
            "    (box_head): TwoMLPHead(\n",
            "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNPredictor(\n",
            "      (cls_score): Linear(in_features=1024, out_features=85, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=340, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXZjdPSiKxe0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "87aecbe3-a4d1-4574-eb7b-d2027d3fbb7b"
      },
      "source": [
        "model.train()\n",
        "img, label = dataset[3]\n",
        "img = img.unsqueeze(0)\n",
        "label = [label]\n",
        "print(img.shape)\n",
        "print(label)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 375, 500])\n",
            "[{'labels': tensor([73, 68]), 'boxes': tensor([[1990,  795, 2297, 1079],\n",
            "        [1579, 1598, 2992, 2363]])}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4CkBE5fK24i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "471289c4-7f44-43ad-88a8-bf92072101f0"
      },
      "source": [
        "out = model(img, label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero(Tensor input, *, Tensor out)\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(Tensor input, *, bool as_tuple)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4bzJSQeOKAt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "21b96def-f580-4481-a806-10f4e6f7e77e"
      },
      "source": [
        "print(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'loss_classifier': tensor(4.3437, grad_fn=<NllLossBackward>), 'loss_box_reg': tensor(1.2882e-05, grad_fn=<DivBackward0>), 'loss_objectness': tensor(20.2147, grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'loss_rpn_box_reg': tensor(244.5419, grad_fn=<DivBackward0>)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRaYZDDhL-xB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_length = int(0.6*len(dataset))\n",
        "train_length = 50\n",
        "#val_length = int(0.2*len(dataset))\n",
        "val_length = 5\n",
        "test_length = len(dataset) - train_length - val_length\n",
        "torch.manual_seed(42)\n",
        "trainset, valset, testst = torch.utils.data.random_split(dataset,\n",
        "                                                         [train_length, val_length, test_length])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuUjGKh0UsK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_fn(batch):\n",
        "  images = []\n",
        "  targets = []\n",
        "  for lego in batch:\n",
        "    images.append(lego[0])\n",
        "    targets.append(lego[1])\n",
        "  \n",
        "  return images, targets\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEQyuPrcRkoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Batcher:\n",
        "    def __init__(self, dataset, batch_size=32, drop_last=False):\n",
        "        self.pics_by_length = {}\n",
        "        for image, target in dataset:\n",
        "            # compute the length of the labels:\n",
        "            llen =target[\"labels\"].shape[0]\n",
        "            # put the data in the correct key inside self.tweet_by_length\n",
        "            if llen not in self.pics_by_length:\n",
        "                self.pics_by_length[llen] = []\n",
        "            self.pics_by_length[llen].append((image, target),)\n",
        "         \n",
        "        #  create a DataLoader for each set of tweets of the same length\n",
        "        self.loaders = {llen : torch.utils.data.DataLoader(\n",
        "                                    legos,\n",
        "                                    batch_size=batch_size,\n",
        "                                    shuffle=True,\n",
        "                                    drop_last=drop_last,   # omit last batch if smaller than batch_size\n",
        "                                    collate_fn=collate_fn)\n",
        "            for llen, legos in self.pics_by_length.items()}\n",
        "        \n",
        "    def __iter__(self): # called by Python to create an iterator\n",
        "        # make an iterator for every tweet length\n",
        "        iters = [iter(loader) for loader in self.loaders.values()]\n",
        "        while iters:\n",
        "            # pick an iterator (a length)\n",
        "            im = random.choice(iters)\n",
        "            try:\n",
        "                yield next(im)\n",
        "            except StopIteration:\n",
        "                # no more elements in the iterator, remove it\n",
        "                iters.remove(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN0gaYHjS_7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = Batcher(trainset, batch_size=5, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4IYCHenJBtc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_loader = Batcher(valset, batch_size=5, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGkboj0RH_jH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_precision(model, dataloader):\n",
        "  model.eval()\n",
        "  count = 0\n",
        "  total_predictions = 0\n",
        "  total_labels = 0\n",
        "  for inputs, target in dataloader:\n",
        "    for i in range(len(inputs)):\n",
        "      inputs[i] = inputs[i].cuda()\n",
        "      target[i][\"labels\"] = target[i][\"labels\"].cuda()\n",
        "      target[i][\"boxes\"] = target[i][\"boxes\"].cuda()\n",
        "  \n",
        "    outputs = model(inputs)\n",
        "    for i in range(len(outputs)):\n",
        "      label = (target[i][\"labels\"]).cpu().numpy()\n",
        "      pred = outputs[i]['labels'].cpu().numpy()\n",
        "      # Get number of true positives:\n",
        "      count += min(npi.in_(pred, label).sum(), npi.in_(pred, label).sum())\n",
        "      # Get total number of predictions:\n",
        "      total_predictions += len(pred)\n",
        "      total_labels += len(label)\n",
        "      print(\"Labels: {}, Predictions: {}\".format(label, pred))\n",
        "  # Precisions = TP/(TP + FP)\n",
        "  print(count, total_predictions, total_labels)\n",
        "  if (total_predictions == 0):\n",
        "    precision = 0\n",
        "  else:\n",
        "    precision = count/total_predictions\n",
        "\n",
        "  if (total_labels == 0):\n",
        "    recall = 0\n",
        "  else:\n",
        "    recall = count/total_labels\n",
        "  return (precision, recall)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15rSZ1EEAQi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, optimizer, trainloader, val_loader, num_epochs=25):\n",
        "    torch.manual_seed(42)\n",
        "    since = time.time()\n",
        "\n",
        "    epochs, train_loss, train_precs, val_precs = [], [], [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        n = 0\n",
        "        for inputs, target in trainloader:\n",
        "            for i in range(len(inputs)):\n",
        "              inputs[i] = inputs[i].cuda()\n",
        "              target[i][\"labels\"] = target[i][\"labels\"].cuda()\n",
        "              target[i][\"boxes\"] = target[i][\"boxes\"].cuda()\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.set_grad_enabled(True):\n",
        "                outputs = model(inputs, target)\n",
        "                class_loss = outputs['loss_classifier']\n",
        "\n",
        "                class_loss.backward()\n",
        "                optimizer.step()\n",
        "                # statistics\n",
        "                running_loss += class_loss.item()\n",
        "                n+=1\n",
        "            if (n % 10 == 0):\n",
        "              print(\"Epoch {}, iteration {}\".format(epoch, n))\n",
        "                  \n",
        "        torch.set_grad_enabled(False)\n",
        "        epoch_loss = running_loss / n\n",
        "        train_loss.append(epoch_loss)\n",
        "        epochs.append(epoch)\n",
        "        train_prec, train_recall = get_precision(model, trainloader)\n",
        "        val_prec, val_recall = get_precision(model, val_loader)\n",
        "        train_precs.append(train_prec)\n",
        "        val_precs.append(val_prec)\n",
        "\n",
        "        print('Training - {} Loss: {:.4f} Prec: {:.4f}'.format(epoch, epoch_loss, train_prec))\n",
        "        print('Validation - {} Prec: {:.4f}'.format(epoch, val_prec))\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    \"\"\"\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    \"\"\"\n",
        "    # plotting\n",
        "    plt.title(\"Training Loss Curve\")\n",
        "    plt.plot(epochs, train_loss, label=\"Train\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Training Precision Curve\")\n",
        "    plt.plot(epochs, train_precs, label=\"Train\")\n",
        "    plt.plot(epochs, val_precs, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ4MMyeI78t8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xo6uGjC6QwZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_ft = optim.Adam(model.parameters(), lr=1e-5)\n",
        "model = model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zHFLgaFNW0C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7fbb7544-751c-4bc0-824a-b886f278411a"
      },
      "source": [
        "model_ft = train_model(model, optimizer_ft, trainloader, val_loader, num_epochs=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/19\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [16 14 54 80 43], Predictions: [29]\n",
            "Labels: [44 75 19 73 20], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: [29]\n",
            "Labels: [71 18 30 49 39], Predictions: [16]\n",
            "Labels: [65 11  6 34 36], Predictions: []\n",
            "Labels: [54 27 55 10 73], Predictions: []\n",
            "Labels: [45 77 66 34 56], Predictions: [29 29 29]\n",
            "Labels: [59 44  7 10 82], Predictions: []\n",
            "Labels: [32  0 30 13 26], Predictions: []\n",
            "Labels: [38], Predictions: []\n",
            "Labels: [70], Predictions: []\n",
            "Labels: [33], Predictions: []\n",
            "Labels: [32], Predictions: []\n",
            "Labels: [65], Predictions: []\n",
            "Labels: [32  0 30 13 26 80], Predictions: []\n",
            "Labels: [49  8 71 84  1 29], Predictions: [29 29]\n",
            "Labels: [40 17 61 12  1 28], Predictions: []\n",
            "Labels: [45 77 66 34 56 24], Predictions: []\n",
            "Labels: [32 19 80 27 21 75], Predictions: [16 41]\n",
            "Labels: [70 51], Predictions: []\n",
            "Labels: [35 74], Predictions: []\n",
            "Labels: [72 12], Predictions: []\n",
            "Labels: [26 56], Predictions: []\n",
            "Labels: [22  3], Predictions: []\n",
            "2 10 95\n",
            "0 0 0\n",
            "Training - 0 Loss: 3.7054 Prec: 0.2000\n",
            "Validation - 0 Prec: 0.0000\n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "Labels: [70], Predictions: []\n",
            "Labels: [37], Predictions: []\n",
            "Labels: [65], Predictions: []\n",
            "Labels: [32], Predictions: [29]\n",
            "Labels: [38], Predictions: []\n",
            "Labels: [38 70], Predictions: [29 52 52]\n",
            "Labels: [22  3], Predictions: []\n",
            "Labels: [72 12], Predictions: []\n",
            "Labels: [35 74], Predictions: []\n",
            "Labels: [70 51], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [16 14 54 80 43], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [65 11  6 34 36], Predictions: []\n",
            "Labels: [32  0 30 13 26], Predictions: []\n",
            "Labels: [22  3  3  8 12  7], Predictions: [29]\n",
            "Labels: [40 17 61 12  1 28], Predictions: []\n",
            "Labels: [45 77 66 34 56 24], Predictions: [29 29 29 29 29]\n",
            "Labels: [32 19 80 27 21 75], Predictions: [5 5]\n",
            "Labels: [16 14 54 80 43 74], Predictions: []\n",
            "Labels: [44 75 19 73 20], Predictions: [29]\n",
            "Labels: [45 77 66 34 56], Predictions: [29 29 29 29 29 29 29 17]\n",
            "Labels: [76 47 62 38 61], Predictions: []\n",
            "Labels: [71 18 30 49 39], Predictions: [29]\n",
            "Labels: [54 27 55 10 73], Predictions: []\n",
            "0 22 95\n",
            "0 0 0\n",
            "Training - 1 Loss: 2.2614 Prec: 0.0000\n",
            "Validation - 1 Prec: 0.0000\n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "Labels: [32  0 30 13 26 80], Predictions: []\n",
            "Labels: [40 17 61 12  1 28], Predictions: []\n",
            "Labels: [32  0 30 13 26 80], Predictions: []\n",
            "Labels: [32 19 80 27 21 75], Predictions: []\n",
            "Labels: [45 77 66 34 56 24], Predictions: []\n",
            "Labels: [37], Predictions: []\n",
            "Labels: [38], Predictions: []\n",
            "Labels: [70], Predictions: []\n",
            "Labels: [65], Predictions: []\n",
            "Labels: [81], Predictions: []\n",
            "Labels: [71 18 30 49 39], Predictions: []\n",
            "Labels: [44 75 19 73 20], Predictions: []\n",
            "Labels: [54 27 55 10 73], Predictions: []\n",
            "Labels: [76 47 62 38 61], Predictions: []\n",
            "Labels: [59 44  7 10 82], Predictions: []\n",
            "Labels: [59 44], Predictions: []\n",
            "Labels: [35 74], Predictions: []\n",
            "Labels: [70 51], Predictions: []\n",
            "Labels: [26 56], Predictions: []\n",
            "Labels: [22  3], Predictions: []\n",
            "Labels: [32  0 30 13 26], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [45 77 66 34 56], Predictions: []\n",
            "Labels: [16 14 54 80 43], Predictions: []\n",
            "Labels: [65 11  6 34 36], Predictions: []\n",
            "0 0 95\n",
            "0 0 0\n",
            "Training - 2 Loss: 0.7357 Prec: 0.0000\n",
            "Validation - 2 Prec: 0.0000\n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "Labels: [32  0 30 13 26 80], Predictions: []\n",
            "Labels: [45 77 66 34 56 24], Predictions: []\n",
            "Labels: [22  3  3  8 12  7], Predictions: []\n",
            "Labels: [32 19 80 27 21 75], Predictions: []\n",
            "Labels: [16 14 54 80 43 74], Predictions: []\n",
            "Labels: [33], Predictions: []\n",
            "Labels: [70], Predictions: []\n",
            "Labels: [37], Predictions: []\n",
            "Labels: [81], Predictions: []\n",
            "Labels: [38], Predictions: []\n",
            "Labels: [71 18 30 49 39], Predictions: []\n",
            "Labels: [45 77 66 34 56], Predictions: []\n",
            "Labels: [54 27 55 10 73], Predictions: []\n",
            "Labels: [59 44  7 10 82], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [76 47 62 38 61], Predictions: []\n",
            "Labels: [65 11  6 34 36], Predictions: []\n",
            "Labels: [16 14 54 80 43], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [32  0 30 13 26], Predictions: []\n",
            "Labels: [70 51], Predictions: []\n",
            "Labels: [22  3], Predictions: []\n",
            "Labels: [35 74], Predictions: []\n",
            "Labels: [46 70], Predictions: []\n",
            "Labels: [26 56], Predictions: []\n",
            "0 0 95\n",
            "0 0 0\n",
            "Training - 3 Loss: 0.1945 Prec: 0.0000\n",
            "Validation - 3 Prec: 0.0000\n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "Labels: [59 44  7 10 82], Predictions: []\n",
            "Labels: [45 77 66 34 56], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [65 11  6 34 36], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [33], Predictions: []\n",
            "Labels: [38], Predictions: []\n",
            "Labels: [65], Predictions: []\n",
            "Labels: [37], Predictions: []\n",
            "Labels: [32], Predictions: []\n",
            "Labels: [49  8 71 84  1 29], Predictions: []\n",
            "Labels: [16 14 54 80 43 74], Predictions: []\n",
            "Labels: [32  0 30 13 26 80], Predictions: []\n",
            "Labels: [40 17 61 12  1 28], Predictions: []\n",
            "Labels: [22  3  3  8 12  7], Predictions: []\n",
            "Labels: [22  3], Predictions: []\n",
            "Labels: [59 44], Predictions: []\n",
            "Labels: [22  3], Predictions: []\n",
            "Labels: [72 12], Predictions: []\n",
            "Labels: [38 70], Predictions: []\n",
            "Labels: [44 75 19 73 20], Predictions: []\n",
            "Labels: [16 14 54 80 43], Predictions: []\n",
            "Labels: [76 47 62 38 61], Predictions: []\n",
            "Labels: [71 18 30 49 39], Predictions: []\n",
            "Labels: [32  0 30 13 26], Predictions: []\n",
            "0 0 95\n",
            "0 0 0\n",
            "Training - 4 Loss: 0.1645 Prec: 0.0000\n",
            "Validation - 4 Prec: 0.0000\n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "Labels: [59 44], Predictions: []\n",
            "Labels: [72 12], Predictions: []\n",
            "Labels: [35 74], Predictions: []\n",
            "Labels: [26 56], Predictions: []\n",
            "Labels: [46 70], Predictions: []\n",
            "Labels: [54 27 55 10 73], Predictions: []\n",
            "Labels: [44 75 19 73 20], Predictions: []\n",
            "Labels: [16 14 54 80 43], Predictions: []\n",
            "Labels: [71 18 30 49 39], Predictions: []\n",
            "Labels: [65 11  6 34 36], Predictions: []\n",
            "Labels: [32  0 30 13 26], Predictions: []\n",
            "Labels: [59 44  7 10 82], Predictions: []\n",
            "Labels: [45 77 66 34 56], Predictions: []\n",
            "Labels: [76 47 62 38 61], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [37], Predictions: []\n",
            "Labels: [38], Predictions: []\n",
            "Labels: [65], Predictions: []\n",
            "Labels: [81], Predictions: []\n",
            "Labels: [32], Predictions: []\n",
            "Labels: [22  3  3  8 12  7], Predictions: []\n",
            "Labels: [32  0 30 13 26 80], Predictions: []\n",
            "Labels: [16 14 54 80 43 74], Predictions: []\n",
            "Labels: [49  8 71 84  1 29], Predictions: []\n",
            "Labels: [32 19 80 27 21 75], Predictions: []\n",
            "0 0 95\n",
            "0 0 0\n",
            "Training - 5 Loss: 0.0961 Prec: 0.0000\n",
            "Validation - 5 Prec: 0.0000\n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "Labels: [65], Predictions: []\n",
            "Labels: [32], Predictions: []\n",
            "Labels: [70], Predictions: []\n",
            "Labels: [37], Predictions: []\n",
            "Labels: [33], Predictions: []\n",
            "Labels: [32  0 30 13 26 80], Predictions: []\n",
            "Labels: [49  8 71 84  1 29], Predictions: []\n",
            "Labels: [16 14 54 80 43 74], Predictions: []\n",
            "Labels: [40 17 61 12  1 28], Predictions: []\n",
            "Labels: [45 77 66 34 56 24], Predictions: []\n",
            "Labels: [71 18 30 49 39], Predictions: []\n",
            "Labels: [65 11  6 34 36], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [16 14 54 80 43], Predictions: []\n",
            "Labels: [44 75 19 73 20], Predictions: []\n",
            "Labels: [26 56], Predictions: []\n",
            "Labels: [22  3], Predictions: []\n",
            "Labels: [38 70], Predictions: []\n",
            "Labels: [72 12], Predictions: []\n",
            "Labels: [35 74], Predictions: []\n",
            "Labels: [45 77 66 34 56], Predictions: []\n",
            "Labels: [76 47 62 38 61], Predictions: []\n",
            "Labels: [54 27 55 10 73], Predictions: []\n",
            "Labels: [32  0 30 13 26], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "0 0 95\n",
            "0 0 0\n",
            "Training - 6 Loss: 0.0563 Prec: 0.0000\n",
            "Validation - 6 Prec: 0.0000\n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "Labels: [81], Predictions: []\n",
            "Labels: [32], Predictions: []\n",
            "Labels: [70], Predictions: []\n",
            "Labels: [37], Predictions: []\n",
            "Labels: [38], Predictions: []\n",
            "Labels: [32  0 30 13 26 80], Predictions: []\n",
            "Labels: [40 17 61 12  1 28], Predictions: []\n",
            "Labels: [32 19 80 27 21 75], Predictions: []\n",
            "Labels: [45 77 66 34 56 24], Predictions: []\n",
            "Labels: [49  8 71 84  1 29], Predictions: []\n",
            "Labels: [59 44], Predictions: []\n",
            "Labels: [46 70], Predictions: []\n",
            "Labels: [26 56], Predictions: []\n",
            "Labels: [22  3], Predictions: []\n",
            "Labels: [35 74], Predictions: []\n",
            "Labels: [54 27 55 10 73], Predictions: []\n",
            "Labels: [59 44  7 10 82], Predictions: []\n",
            "Labels: [32  0 30 13 26], Predictions: []\n",
            "Labels: [44 75 19 73 20], Predictions: []\n",
            "Labels: [65 11  6 34 36], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [45 77 66 34 56], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [71 18 30 49 39], Predictions: []\n",
            "Labels: [16 14 54 80 43], Predictions: []\n",
            "0 0 95\n",
            "0 0 0\n",
            "Training - 7 Loss: 0.0412 Prec: 0.0000\n",
            "Validation - 7 Prec: 0.0000\n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "Labels: [22  3], Predictions: []\n",
            "Labels: [72 12], Predictions: []\n",
            "Labels: [70 51], Predictions: []\n",
            "Labels: [22  3], Predictions: []\n",
            "Labels: [46 70], Predictions: []\n",
            "Labels: [32  0 30 13 26 80], Predictions: []\n",
            "Labels: [49  8 71 84  1 29], Predictions: []\n",
            "Labels: [22  3  3  8 12  7], Predictions: []\n",
            "Labels: [40 17 61 12  1 28], Predictions: []\n",
            "Labels: [45 77 66 34 56 24], Predictions: []\n",
            "Labels: [44 75 19 73 20], Predictions: []\n",
            "Labels: [54 27 55 10 73], Predictions: []\n",
            "Labels: [65 11  6 34 36], Predictions: []\n",
            "Labels: [71 18 30 49 39], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [45 77 66 34 56], Predictions: []\n",
            "Labels: [16 14 54 80 43], Predictions: []\n",
            "Labels: [32  0 30 13 26], Predictions: []\n",
            "Labels: [76 47 62 38 61], Predictions: []\n",
            "Labels: [37], Predictions: []\n",
            "Labels: [65], Predictions: []\n",
            "Labels: [32], Predictions: []\n",
            "Labels: [38], Predictions: []\n",
            "Labels: [33], Predictions: []\n",
            "0 0 95\n",
            "0 0 0\n",
            "Training - 8 Loss: 0.0347 Prec: 0.0000\n",
            "Validation - 8 Prec: 0.0000\n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "Labels: [44 75 19 73 20], Predictions: []\n",
            "Labels: [65 11  6 34 36], Predictions: []\n",
            "Labels: [32  0 30 13 26], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [45 77 66 34 56], Predictions: []\n",
            "Labels: [76 47 62 38 61], Predictions: []\n",
            "Labels: [59 44  7 10 82], Predictions: []\n",
            "Labels: [16 14 54 80 43], Predictions: []\n",
            "Labels: [71 18 30 49 39], Predictions: []\n",
            "Labels: [54 27 55 10 73], Predictions: []\n",
            "Labels: [37], Predictions: []\n",
            "Labels: [32], Predictions: []\n",
            "Labels: [33], Predictions: []\n",
            "Labels: [70], Predictions: []\n",
            "Labels: [81], Predictions: []\n",
            "Labels: [59 44], Predictions: []\n",
            "Labels: [70 51], Predictions: []\n",
            "Labels: [35 74], Predictions: []\n",
            "Labels: [38 70], Predictions: []\n",
            "Labels: [26 56], Predictions: []\n",
            "Labels: [32  0 30 13 26 80], Predictions: []\n",
            "Labels: [40 17 61 12  1 28], Predictions: []\n",
            "Labels: [22  3  3  8 12  7], Predictions: []\n",
            "Labels: [32  0 30 13 26 80], Predictions: []\n",
            "Labels: [45 77 66 34 56 24], Predictions: []\n",
            "0 0 95\n",
            "0 0 0\n",
            "Training - 9 Loss: 0.0333 Prec: 0.0000\n",
            "Validation - 9 Prec: 0.0000\n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "Labels: [32  0 30 13 26 80], Predictions: []\n",
            "Labels: [32  0 30 13 26 80], Predictions: []\n",
            "Labels: [49  8 71 84  1 29], Predictions: []\n",
            "Labels: [32 19 80 27 21 75], Predictions: []\n",
            "Labels: [22  3  3  8 12  7], Predictions: []\n",
            "Labels: [22  3], Predictions: []\n",
            "Labels: [70 51], Predictions: []\n",
            "Labels: [38 70], Predictions: []\n",
            "Labels: [26 56], Predictions: []\n",
            "Labels: [46 70], Predictions: []\n",
            "Labels: [32], Predictions: []\n",
            "Labels: [70], Predictions: []\n",
            "Labels: [38], Predictions: []\n",
            "Labels: [65], Predictions: []\n",
            "Labels: [37], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [59 44  7 10 82], Predictions: []\n",
            "Labels: [65 11  6 34 36], Predictions: []\n",
            "Labels: [45 77 66 34 56], Predictions: []\n",
            "Labels: [54 27 55 10 73], Predictions: []\n",
            "Labels: [44 75 19 73 20], Predictions: []\n",
            "Labels: [32  0 30 13 26], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [71 18 30 49 39], Predictions: []\n",
            "Labels: [16 14 54 80 43], Predictions: []\n",
            "0 0 95\n",
            "0 0 0\n",
            "Training - 10 Loss: 0.0325 Prec: 0.0000\n",
            "Validation - 10 Prec: 0.0000\n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "Labels: [65], Predictions: []\n",
            "Labels: [37], Predictions: []\n",
            "Labels: [70], Predictions: []\n",
            "Labels: [33], Predictions: []\n",
            "Labels: [38], Predictions: []\n",
            "Labels: [70 51], Predictions: []\n",
            "Labels: [46 70], Predictions: []\n",
            "Labels: [72 12], Predictions: []\n",
            "Labels: [38 70], Predictions: []\n",
            "Labels: [35 74], Predictions: []\n",
            "Labels: [32  0 30 13 26 80], Predictions: []\n",
            "Labels: [32  0 30 13 26 80], Predictions: []\n",
            "Labels: [16 14 54 80 43 74], Predictions: []\n",
            "Labels: [40 17 61 12  1 28], Predictions: []\n",
            "Labels: [45 77 66 34 56 24], Predictions: []\n",
            "Labels: [54 27 55 10 73], Predictions: []\n",
            "Labels: [32  0 30 13 26], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [71 18 30 49 39], Predictions: []\n",
            "Labels: [59 44  7 10 82], Predictions: []\n",
            "Labels: [65 11  6 34 36], Predictions: []\n",
            "Labels: [16 14 54 80 43], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [76 47 62 38 61], Predictions: []\n",
            "Labels: [45 77 66 34 56], Predictions: []\n",
            "0 0 95\n",
            "0 0 0\n",
            "Training - 11 Loss: 0.0326 Prec: 0.0000\n",
            "Validation - 11 Prec: 0.0000\n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "Labels: [22  3  3  8 12  7], Predictions: []\n",
            "Labels: [49  8 71 84  1 29], Predictions: []\n",
            "Labels: [32  0 30 13 26 80], Predictions: []\n",
            "Labels: [32 19 80 27 21 75], Predictions: []\n",
            "Labels: [45 77 66 34 56 24], Predictions: []\n",
            "Labels: [32  0 30 13 26], Predictions: []\n",
            "Labels: [59 44  7 10 82], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [54 27 55 10 73], Predictions: []\n",
            "Labels: [16 14 54 80 43], Predictions: []\n",
            "Labels: [76 47 62 38 61], Predictions: []\n",
            "Labels: [71 18 30 49 39], Predictions: []\n",
            "Labels: [45 77 66 34 56], Predictions: []\n",
            "Labels: [65 11  6 34 36], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [38 70], Predictions: []\n",
            "Labels: [35 74], Predictions: []\n",
            "Labels: [72 12], Predictions: []\n",
            "Labels: [22  3], Predictions: []\n",
            "Labels: [70 51], Predictions: []\n",
            "Labels: [81], Predictions: []\n",
            "Labels: [37], Predictions: []\n",
            "Labels: [32], Predictions: []\n",
            "Labels: [65], Predictions: []\n",
            "Labels: [70], Predictions: []\n",
            "0 0 95\n",
            "0 0 0\n",
            "Training - 12 Loss: 0.0338 Prec: 0.0000\n",
            "Validation - 12 Prec: 0.0000\n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "Labels: [76 47 62 38 61], Predictions: []\n",
            "Labels: [44 75 19 73 20], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [59 44  7 10 82], Predictions: []\n",
            "Labels: [71 18 30 49 39], Predictions: []\n",
            "Labels: [16 14 54 80 43 74], Predictions: []\n",
            "Labels: [32  0 30 13 26 80], Predictions: []\n",
            "Labels: [32  0 30 13 26 80], Predictions: []\n",
            "Labels: [22  3  3  8 12  7], Predictions: []\n",
            "Labels: [40 17 61 12  1 28], Predictions: []\n",
            "Labels: [72 12], Predictions: []\n",
            "Labels: [59 44], Predictions: []\n",
            "Labels: [26 56], Predictions: []\n",
            "Labels: [35 74], Predictions: []\n",
            "Labels: [38 70], Predictions: []\n",
            "Labels: [81], Predictions: []\n",
            "Labels: [65], Predictions: []\n",
            "Labels: [33], Predictions: []\n",
            "Labels: [37], Predictions: []\n",
            "Labels: [70], Predictions: []\n",
            "Labels: [16 14 54 80 43], Predictions: []\n",
            "Labels: [32  0 30 13 26], Predictions: []\n",
            "Labels: [65 11  6 34 36], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [54 27 55 10 73], Predictions: []\n",
            "0 0 95\n",
            "0 0 0\n",
            "Training - 13 Loss: 0.0323 Prec: 0.0000\n",
            "Validation - 13 Prec: 0.0000\n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "Labels: [38 70], Predictions: []\n",
            "Labels: [59 44], Predictions: []\n",
            "Labels: [72 12], Predictions: []\n",
            "Labels: [35 74], Predictions: []\n",
            "Labels: [70 51], Predictions: []\n",
            "Labels: [16 14 54 80 43 74], Predictions: []\n",
            "Labels: [32 19 80 27 21 75], Predictions: []\n",
            "Labels: [22  3  3  8 12  7], Predictions: []\n",
            "Labels: [49  8 71 84  1 29], Predictions: []\n",
            "Labels: [32  0 30 13 26 80], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [65 11  6 34 36], Predictions: []\n",
            "Labels: [71 18 30 49 39], Predictions: []\n",
            "Labels: [76 47 62 38 61], Predictions: []\n",
            "Labels: [54 27 55 10 73], Predictions: []\n",
            "Labels: [59 44  7 10 82], Predictions: []\n",
            "Labels: [45 77 66 34 56], Predictions: []\n",
            "Labels: [16 14 54 80 43], Predictions: []\n",
            "Labels: [44 75 19 73 20], Predictions: []\n",
            "Labels: [32  0 30 13 26], Predictions: []\n",
            "Labels: [70], Predictions: []\n",
            "Labels: [32], Predictions: []\n",
            "Labels: [38], Predictions: []\n",
            "Labels: [65], Predictions: []\n",
            "Labels: [37], Predictions: []\n",
            "0 0 95\n",
            "0 0 0\n",
            "Training - 14 Loss: 0.0321 Prec: 0.0000\n",
            "Validation - 14 Prec: 0.0000\n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "Labels: [38], Predictions: []\n",
            "Labels: [81], Predictions: []\n",
            "Labels: [32], Predictions: []\n",
            "Labels: [37], Predictions: []\n",
            "Labels: [70], Predictions: []\n",
            "Labels: [40 17 61 12  1 28], Predictions: []\n",
            "Labels: [22  3  3  8 12  7], Predictions: []\n",
            "Labels: [45 77 66 34 56 24], Predictions: []\n",
            "Labels: [32 19 80 27 21 75], Predictions: []\n",
            "Labels: [32  0 30 13 26 80], Predictions: []\n",
            "Labels: [70 51], Predictions: []\n",
            "Labels: [22  3], Predictions: []\n",
            "Labels: [26 56], Predictions: []\n",
            "Labels: [72 12], Predictions: []\n",
            "Labels: [22  3], Predictions: []\n",
            "Labels: [59 44  7 10 82], Predictions: []\n",
            "Labels: [54 27 55 10 73], Predictions: []\n",
            "Labels: [71 18 30 49 39], Predictions: []\n",
            "Labels: [76 47 62 38 61], Predictions: []\n",
            "Labels: [65 11  6 34 36], Predictions: []\n",
            "Labels: [45 77 66 34 56], Predictions: []\n",
            "Labels: [44 75 19 73 20], Predictions: []\n",
            "Labels: [16 14 54 80 43], Predictions: []\n",
            "Labels: [32  0 30 13 26], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "0 0 95\n",
            "0 0 0\n",
            "Training - 15 Loss: 0.0327 Prec: 0.0000\n",
            "Validation - 15 Prec: 0.0000\n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "Labels: [37], Predictions: []\n",
            "Labels: [32], Predictions: []\n",
            "Labels: [65], Predictions: []\n",
            "Labels: [81], Predictions: []\n",
            "Labels: [38], Predictions: []\n",
            "Labels: [40 17 61 12  1 28], Predictions: []\n",
            "Labels: [16 14 54 80 43 74], Predictions: []\n",
            "Labels: [32 19 80 27 21 75], Predictions: []\n",
            "Labels: [22  3  3  8 12  7], Predictions: []\n",
            "Labels: [45 77 66 34 56 24], Predictions: []\n",
            "Labels: [38 70], Predictions: []\n",
            "Labels: [22  3], Predictions: []\n",
            "Labels: [26 56], Predictions: []\n",
            "Labels: [59 44], Predictions: []\n",
            "Labels: [46 70], Predictions: []\n",
            "Labels: [71 18 30 49 39], Predictions: []\n",
            "Labels: [32  0 30 13 26], Predictions: []\n",
            "Labels: [44 75 19 73 20], Predictions: []\n",
            "Labels: [54 27 55 10 73], Predictions: []\n",
            "Labels: [76 47 62 38 61], Predictions: []\n",
            "Labels: [59 44  7 10 82], Predictions: []\n",
            "Labels: [16 14 54 80 43], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [65 11  6 34 36], Predictions: []\n",
            "Labels: [45 77 66 34 56], Predictions: []\n",
            "0 0 95\n",
            "0 0 0\n",
            "Training - 16 Loss: 0.0329 Prec: 0.0000\n",
            "Validation - 16 Prec: 0.0000\n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "Labels: [22  3  3  8 12  7], Predictions: []\n",
            "Labels: [32 19 80 27 21 75], Predictions: []\n",
            "Labels: [32  0 30 13 26 80], Predictions: []\n",
            "Labels: [40 17 61 12  1 28], Predictions: []\n",
            "Labels: [16 14 54 80 43 74], Predictions: []\n",
            "Labels: [22  3], Predictions: []\n",
            "Labels: [70 51], Predictions: []\n",
            "Labels: [35 74], Predictions: []\n",
            "Labels: [38 70], Predictions: []\n",
            "Labels: [26 56], Predictions: []\n",
            "Labels: [32  0 30 13 26], Predictions: []\n",
            "Labels: [65 11  6 34 36], Predictions: []\n",
            "Labels: [54 27 55 10 73], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [59 44  7 10 82], Predictions: []\n",
            "Labels: [16 14 54 80 43], Predictions: []\n",
            "Labels: [44 75 19 73 20], Predictions: []\n",
            "Labels: [76 47 62 38 61], Predictions: []\n",
            "Labels: [45 77 66 34 56], Predictions: []\n",
            "Labels: [71 18 30 49 39], Predictions: []\n",
            "Labels: [70], Predictions: []\n",
            "Labels: [33], Predictions: []\n",
            "Labels: [81], Predictions: []\n",
            "Labels: [65], Predictions: []\n",
            "Labels: [37], Predictions: []\n",
            "0 0 95\n",
            "0 0 0\n",
            "Training - 17 Loss: 0.0331 Prec: 0.0000\n",
            "Validation - 17 Prec: 0.0000\n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "Labels: [59 44], Predictions: []\n",
            "Labels: [22  3], Predictions: []\n",
            "Labels: [46 70], Predictions: []\n",
            "Labels: [72 12], Predictions: []\n",
            "Labels: [38 70], Predictions: []\n",
            "Labels: [44 75 19 73 20], Predictions: []\n",
            "Labels: [45 77 66 34 56], Predictions: []\n",
            "Labels: [71 18 30 49 39], Predictions: []\n",
            "Labels: [16 14 54 80 43], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [37], Predictions: []\n",
            "Labels: [38], Predictions: []\n",
            "Labels: [65], Predictions: []\n",
            "Labels: [33], Predictions: []\n",
            "Labels: [70], Predictions: []\n",
            "Labels: [32 19 80 27 21 75], Predictions: []\n",
            "Labels: [40 17 61 12  1 28], Predictions: []\n",
            "Labels: [16 14 54 80 43 74], Predictions: []\n",
            "Labels: [32  0 30 13 26 80], Predictions: []\n",
            "Labels: [45 77 66 34 56 24], Predictions: []\n",
            "Labels: [65 11  6 34 36], Predictions: []\n",
            "Labels: [59 44  7 10 82], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [54 27 55 10 73], Predictions: []\n",
            "Labels: [32  0 30 13 26], Predictions: []\n",
            "0 0 95\n",
            "0 0 0\n",
            "Training - 18 Loss: 0.0327 Prec: 0.0000\n",
            "Validation - 18 Prec: 0.0000\n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "Labels: [45 77 66 34 56], Predictions: []\n",
            "Labels: [54 27 55 10 73], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [49  8 71 84  1], Predictions: []\n",
            "Labels: [65 11  6 34 36], Predictions: []\n",
            "Labels: [33], Predictions: []\n",
            "Labels: [81], Predictions: []\n",
            "Labels: [32], Predictions: []\n",
            "Labels: [70], Predictions: []\n",
            "Labels: [37], Predictions: []\n",
            "Labels: [16 14 54 80 43 74], Predictions: []\n",
            "Labels: [32 19 80 27 21 75], Predictions: []\n",
            "Labels: [49  8 71 84  1 29], Predictions: []\n",
            "Labels: [40 17 61 12  1 28], Predictions: []\n",
            "Labels: [45 77 66 34 56 24], Predictions: []\n",
            "Labels: [46 70], Predictions: []\n",
            "Labels: [70 51], Predictions: []\n",
            "Labels: [35 74], Predictions: []\n",
            "Labels: [72 12], Predictions: []\n",
            "Labels: [38 70], Predictions: []\n",
            "Labels: [59 44  7 10 82], Predictions: []\n",
            "Labels: [32  0 30 13 26], Predictions: []\n",
            "Labels: [71 18 30 49 39], Predictions: []\n",
            "Labels: [44 75 19 73 20], Predictions: []\n",
            "Labels: [16 14 54 80 43], Predictions: []\n",
            "0 0 95\n",
            "0 0 0\n",
            "Training - 19 Loss: 0.0320 Prec: 0.0000\n",
            "Validation - 19 Prec: 0.0000\n",
            "\n",
            "Training complete in 7m 25s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS9hndTWyvXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FastRCNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(FastRCNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(4096, num_classes*4)\n",
        "        self.fc2 = nn.Linear(4096, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHD6h9VD0QIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for each pixel on the feature map, need to generate 9 anchor boxes\n",
        "# feed in the center point of the feature\n",
        "# output the x1, y1, x2, y2 coordinates for each box\n",
        "\n",
        "class RPN(nn.Module):\n",
        "    def __init__(self, ratio=[0.5, 1, 2], anchor_size=[8, 16, 32]):\n",
        "        Super(RPN, self).__init__()\n",
        "        self.ratio = ratio\n",
        "        self.anchor_size = anchor_size\n",
        "        self.num_anchors = len(ratio)*len(anchor_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}